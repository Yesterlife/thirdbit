---
title: ""
date: 2019-12-20 05:24:00
---

Back in 1975, Fred Brooks wrote:

> Show me your flowcharts and conceal your tables,
> and I shall continue to be mystified;
> show me your tables and I won't usually need your flowcharts:
> they'll be obvious.

Along the same lines,
telling me the terms that someone needs to know in order to understand something
is a quick and dirty way to figure out what a lesson about that thing needs to cover.
I have therefore gone through two dozen empirical studies on software engineering
and pulled out the terms they use that computer science undergraduates are unlikely to know.
It's an intimidating list,
but if we want to teach software engineers how to
[apply data science to software engineering problems](http://ds4se.tech)
and understand empirical software engineering research,
I think we'll have to cover most of it.

<table>
  <tr>
    <td>
      accuracy<br/>
      alternative hypothesis<br/>
      Amdahl's Law<br/>
      analysis of variance<br/>
      Bayes' Rule<br/>
      Benjamini-Hochberg p-value correction<br/>
      Bernoulli distribution<br/>
      Bessel correction<br/>
      binomial distribution<br/>
      Bonferroni correction<br/>
      box-and-whisker plot<br/>
      central moment<br/>
      Chebyshev's Inequality<br/>
      chi-square test<br/>
      Cliff's Î´<br/>
      Cohen's d<br/>
      Cohen's kappa<br/>
      conditional probability<br/>
      confidence interval<br/>
      continuity correction<br/>
      convergence<br/>
      correlation coefficient<br/>
      covariance<br/>
      covariance matrix<br/>
      cumulative distribution function<br/>
      dataframe<br/>
      degrees of freedom<br/>
      dependent variable<br/>
      descriptive statistics<br/>
      effect size<br/>
      expected value<br/>
      explanatory variable<br/>
      F-measure<br/>
      F-test<br/>
      false negative<br/>
      false positive<br/>
      Gamma distribution<br/>
      Gamma function<br/>
      geometric distribution<br/>
      goal-question-metric<br/>
      Greenhouse-Geisser correction<br/>
      harmonic mean<br/>
      histogram<br/>
      independent variable<br/>
      interquartile range<br/>
      Kano scale<br/>
      Kruskal-Wallis test<br/>
      Likert scale<br/>
      linear regression<br/>
      logistic regression<br/>
      long tail<br/>
      Mann-Whitney U test<br/>
      Mauchly's test for sphericity<br/>
      maximum likelihood estimation
    </td>
    <td>
      mean<br/>
      median<br/>
      method of moments<br/>
      multiple linear regression<br/>
      n-gram analysis<br/>
      negative binomial distribution<br/>
      negative binomial regression<br/>
      Noble's Rules<br/>
      Not a Number<br/>
      normal distribution<br/>
      nuisance factor<br/>
      null hypothesis<br/>
      one-sided distribution<br/>
      outlier<br/>
      overdispersion<br/>
      quartile<br/>
      p hacking<br/>
      p value<br/>
      Poisson distribution<br/>
      pooled sample variance<br/>
      population<br/>
      population moment<br/>
      power law distribution<br/>
      precision<br/>
      principal component analysis<br/>
      probability density function<br/>
      probability mass function<br/>
      quartile<br/>
      rank correlation<br/>
      recall<br/>
      response variable<br/>
      sample<br/>
      sample moment<br/>
      sample variance<br/>
      Shapiro-Wilk test<br/>
      sigmoidal curve<br/>
      Spearman's rank correlation<br/>
      standard deviation<br/>
      standard normal distribution<br/>
      standard uniform distribution<br/>
      statistic<br/>
      statistical model<br/>
      t-distribution<br/>
      t-test<br/>
      tidy data<br/>
      uniform distribution<br/>
      variance<br/>
      variance<br/>
      violin plot<br/>
      Wilcoxon rank-sum test<br/>
      Wilcoxon signed rank test<br/>
      z-test<br/>
      Zipf's Law<br/>
      Zipf-Mandelbrot distribution
    </td>
  </tr>
</table>
